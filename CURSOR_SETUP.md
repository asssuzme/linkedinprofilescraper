# Setup in Cursor IDE

## üöÄ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/asssuzme/linkedinprofilescraper.git
cd linkedinprofilescraper

# Checkout the feature branch
git checkout claude/linkedin-profile-scraper-011CUe2EfsfHmy2VeQm4Zffz
```

### 2. Install Dependencies

```bash
# Install Python packages
pip install -r requirements.txt

# Install Playwright browsers
python -m playwright install chromium
```

### 3. Configure Authentication

**Option A: Using Your Cookie (Quick & Secure)**

Create `cookies.json`:
```json
[
  {
    "name": "li_at",
    "value": "AQEDAV4NWSwCSzSOAAABmOFrM6AAAAGaWsVk1lYAggQUBtjXPkD7M0Sr_CHXhMaWziMUGlHvtmzek8FBjb8mkzL5mT82tR35PY28DFeLkFYsDGSpiYLl3NA3uMp0On_WPVg_0l9Wzbl8i9vz8VkmLVD5",
    "domain": ".linkedin.com",
    "path": "/",
    "expires": 1767225600,
    "httpOnly": true,
    "secure": true,
    "sameSite": "None"
  }
]
```

Create `.env`:
```bash
LINKEDIN_COOKIES=cookies.json
HEADLESS=true
DELAY_BETWEEN_PROFILES=5
MAX_PROFILES=100
```

**Option B: Using Email/Password**

Create `.env`:
```bash
LINKEDIN_EMAIL=your_email@example.com
LINKEDIN_PASSWORD=your_password
HEADLESS=true
DELAY_BETWEEN_PROFILES=5
MAX_PROFILES=100
```

### 4. Run the Scraper

**Scrape Ashutosh Lath's Profile:**
```bash
python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/" -o ashutosh_lath.json
```

**Watch it run (visible browser):**
```bash
# Temporarily set headless to false
python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/" --headless=false
```

### 5. View Results

```bash
# Results saved in output directory
cat output/ashutosh_lath.json

# Or check the auto-generated file
ls -la output/
```

---

## üìä What Gets Extracted

The scraper will extract comprehensive data including:

‚úÖ **Profile Info**
- Full name, headline, location
- Connections, followers count
- Profile picture (multiple resolutions)
- Public identifier & URN

‚úÖ **Contact Information**
- Email address (if visible)
- Phone number (if visible)

‚úÖ **Current Job**
- Job title
- Company name & details
- Industry, website
- Job duration (e.g., "2 yrs 3 mos")

‚úÖ **Work Experience**
- Complete job history
- Multiple roles per company
- Job descriptions
- Employment dates & durations

‚úÖ **Education**
- Schools/Universities
- Degrees & fields of study
- Graduation dates
- Additional details (GPA, activities, etc.)

‚úÖ **Skills & Expertise**
- All skills listed
- Endorsement counts
- Top 5 skills by endorsements
- Skills used at specific companies

‚úÖ **Certifications & Licenses**
- Certificate names
- Issuing organizations
- Issue dates & expiration
- Credential URLs

‚úÖ **Languages**
- Language names
- Proficiency levels

‚úÖ **Recommendations**
- Received recommendations
- Recommendation text
- Recommender details
- Given recommendations

‚úÖ **Interests**
- Companies followed
- Groups joined
- Schools followed
- Newsletters subscribed
- Top voices followed

---

## üéØ Example Commands

```bash
# Single profile with default output location
python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/"

# Single profile with custom output
python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/" -o results/profile.json

# Multiple profiles from file
cat > profiles.json << 'EOF'
[
  {"url": "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/"},
  {"url": "https://www.linkedin.com/in/another-profile/"}
]
EOF

python main.py -i profiles.json -o results/batch.json

# Run in visible browser mode (for debugging)
HEADLESS=false python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/"

# Scrape with longer delays (avoid rate limiting)
echo "DELAY_BETWEEN_PROFILES=10" >> .env
python main.py -i profiles.json
```

---

## üìÅ Project Structure

```
linkedinprofilescraper/
‚îú‚îÄ‚îÄ main.py                   # CLI entry point - START HERE
‚îú‚îÄ‚îÄ scraper.py                # Core scraping logic (43KB)
‚îú‚îÄ‚îÄ parsers.py                # Data parsing utilities
‚îú‚îÄ‚îÄ config.py                 # Configuration management
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ .env                      # Your configuration (create this)
‚îú‚îÄ‚îÄ cookies.json              # Authentication cookies (create this)
‚îú‚îÄ‚îÄ example_input.json        # Example input format
‚îú‚îÄ‚îÄ output/                   # Results saved here
‚îÇ   ‚îî‚îÄ‚îÄ profiles_*.json
‚îÇ
‚îú‚îÄ‚îÄ README.md                 # Full documentation
‚îú‚îÄ‚îÄ RUN_INSTRUCTIONS.md       # Detailed setup guide
‚îú‚îÄ‚îÄ OUTPUT_SCHEMA.md          # Output format reference
‚îú‚îÄ‚îÄ TROUBLESHOOTING.md        # Common issues
‚îú‚îÄ‚îÄ CONTRIBUTING.md           # Contribution guidelines
‚îî‚îÄ‚îÄ setup.sh                  # Automated setup script
```

---

## ‚ö° Quick Setup Script

Or just run the automated setup:

```bash
# Make setup script executable
chmod +x setup.sh

# Run setup
./setup.sh

# Edit .env with your credentials
nano .env

# Run scraper
python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/"
```

---

## üîç Debugging Tips

### If authentication fails:
```bash
# Run in non-headless mode to see what's happening
HEADLESS=false python main.py -u "https://www.linkedin.com/in/test/"

# Check if cookies are valid
cat cookies.json

# Try with email/password instead
rm cookies.json
# Edit .env with LINKEDIN_EMAIL and LINKEDIN_PASSWORD
```

### If scraping is slow:
```bash
# Reduce delays in config.py or .env
echo "DELAY_BETWEEN_PROFILES=2" >> .env

# Skip detailed sections (edit scraper.py)
# Comment out sections you don't need
```

### If data is missing:
- Some profiles have privacy settings
- LinkedIn layout may have changed
- Run in non-headless mode to inspect
- Check TROUBLESHOOTING.md

---

## üö® Important Notes

‚ö†Ô∏è **Security:**
- Never commit `cookies.json` or `.env` to git
- Keep your LinkedIn session secure
- Cookies expire - refresh periodically

‚ö†Ô∏è **Rate Limiting:**
- Don't scrape too aggressively
- Use 5-10 second delays between profiles
- Limit to 50-100 profiles per session
- Respect LinkedIn's Terms of Service

‚ö†Ô∏è **Legal & Ethical:**
- This is for educational/research purposes
- Only scrape public profile data
- Don't use for spam or harassment
- Consider using LinkedIn's official API for commercial use

---

## üéì Learn More

- **README.md** - Complete user guide
- **OUTPUT_SCHEMA.md** - Every field explained
- **TROUBLESHOOTING.md** - Solutions to common problems
- **scraper.py:520** - Where the magic happens

---

## üí° Pro Tips

1. **Start Small**: Test with 1-2 profiles first
2. **Monitor First Run**: Use `HEADLESS=false` to watch it work
3. **Save Progress**: Results are saved after each profile
4. **Batch Wisely**: Process in small batches (20-50 profiles)
5. **Check Output**: Verify data quality before scaling up

---

**Ready to scrape!** üöÄ

Just run:
```bash
python main.py -u "https://www.linkedin.com/in/ashutosh-lath-3a374b2b3/"
```
